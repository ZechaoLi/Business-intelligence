
# 什么是监督学习，无监督学习，半监督学习
- 1. 有监督学习就是训练的数据是已经带有标签的，然后通过模型训练学习输入数据与对应标签之间的关系，比如分类和回归模型
  2. 数据是不带标签的，也就是说对全部数据直接输入模型进行训练，必须常见的聚类
  3. 使用的数据，一部分是标记过的，而大部分是没有标记的。和监督学习相比较，半监督学习的成本较低，但是又能达到较高的准确度。

# K-means中的k值如何选取
- 	Kmeans 中的K是超参数，选K值主要有以下的方法：
	1. 考虑数据的先验知识，或者做简单的数据分析后，凭借经验值给定。
	2. 使用手肘法，手肘法的核心思想是：随着聚类数k的增大，样本划分会更加精细，每个簇的聚合程度会逐渐提高，那么误差平方和SSE自然会逐渐变小。并且，当k小于真实聚类数时，由于k的增大会大幅增加每个簇的聚合程度，故SSE的下降幅度会很大，而当k到达真实聚类数时，再增加k所得到的聚合程度回报会迅速变小，所以SSE的下降幅度会骤减，然后随着k值的继续增大而趋于平缓，也就是说SSE和k的关系图是一个手肘的形状，而这个肘部对应的k值就是数据的真实聚类数。
	3. 使用轮廓系数，用Xi到某个簇所有样本平均距离作为衡量该点到该簇的距离后，选择离Xi最近的一个簇作为最近簇。求出所有样本的轮廓系数后再求平均值就得到了平均轮廓系数。平均轮廓系数的取值范围为[-1,1]，且簇内样本的距离越近，簇间样本距离越远，平均轮廓系数越大，聚类效果越好。那么，很自然地，平均轮廓系数最大的k便是最佳聚类数

# 随机森林采用了bagging集成学习，bagging指的是什么
- 利用重采样的方法，多次采样并且去训练多个模型，组合成一个模型的bag,最后模型预测结果使用多个模型的结果投票，选取类别最多的作为结果。


# 主动学习和半监督学习的区别是什么
- 主动学习是通过少量数据训练出的模型，通过该模型去预测大量未标注数据，再根据决策手段（例如选取模型比较难判定），选出候选数据集去给专家进行标注，然后再加入训练集进行训练，其目的主要是为了减少数据标注量。半监督	学习是将监督学习和无监督学习相结合的一种学习方法。主要考虑的是如何利用少量的标注样本和大量的未标注样本进行训练和分类的问题。

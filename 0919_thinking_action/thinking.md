
# 在CTR点击率预估中，使用GBDT+LR的原理是什么？
- 因为任务是CTR点击率预估，在推荐系统中属于排序模型，所以GBDT + LR主要作为精排的模型。它主要是融合stacking的思想，GBDT主要是基于树形结构，数据敏感度较高，部分数据的调整会引发真题的别的变化，可处理数据量有限，所以需要一个比较钝化的模型，这里就有了LR模型，它的并行能力很强，能够处理较大的数据集，但同时只能处理一维的特征，学习能力有限。这两个模型刚好可以互补，把GBDT每次迭代的叶子结点结果拼接后作为LR模型的数据特征来完成整个CTR模型的训练。

# Wide & Deep的模型结构是怎样的，为什么能通过具备记忆和泛化能力（memorization and generalization）
- Wide & Deep模型的结构主要分为Wide和Deep两部分，wide部分就是一个广义线性模型，其特征组合是需要人为去设定，具体哪些特征需要做交叉，从而实现记忆能力。Deep部分为深度神经网络，它的输入是将原始数据做了低维潜入，因为它是一个前馈网络模型，在模型训练的过程中，embedding的参数也会更新，所以当模型遇到没见过的特征是，可以通过embedding后的向量完成预测，这就是模型泛化的能力。

# 在CTR预估中，使用FM与DNN结合的方式，有哪些结合的方式，代表模型有哪些？
- NFM：一种特殊的embedding+MLP，其要求第一层嵌入后的各领域特征维度一致，并且嵌入权重的初始化是FM预训练好的，串型结构，把FM的结果作为DNN的输入
- DeepFM：将考虑领域信息的FM部分与MLP部分，其实就是对两个模型进行联合训练。
- AFM：通过在逐元素乘法之后形成的向量进行加权求和，而且权重是基于网络自身来产生的。其方法是引入一个注意力子网络（Attention Net），当权重都相等时，AFM退化成无全连接层的NFM。

# GBDT和随机森林都是基于树的算法，它们有什么区别？
- 它们都是基于集成学习的树模型算法，随机森林是属于bagging的思路，将多棵决策树的结果进行投票后得到最终的结果，对不同的树的训练结果没有做进一步的优化提升。而GBDT是属于boosting的思路，在迭代的每一步构建弱学习器弥补原有模型的不足。GBDT中的Gradient Boost就是通过每次迭代的时候构建一个沿梯度下降最快的方向的学习器。并且通过设置不同的损失函数可以处理各类学习任务（多分类、回归等）。


# item流行度在推荐系统中有怎样的应用

- 根据流行度可以在数据集中发现一些规律，例如在movielens里面，高流行度的item所占比例很小，低流行度的item评分差异大，在高流行度的item评分差异小。在冷启动问题上，可以采用基于流行度的推荐，另外在推荐系统中计算相似度也能根据流行度加权重，

# 参数共享指的是什么？
- 这里参数共享指的是在卷积神经网络中，遍历整个图片的时候，每个卷积核fitter的参数是固定不变的，就是说整个图片共享了相同的权值。


# 为什么会用到batch normalization ?
- 因为在神经网络中，每层网络的中间结果都会经过矩阵乘法及非线性运算后再输入激活函数，计算后数据的分布往往都会有所改变，随着网络的多层运算后，数据的分布变化会越来越大，所以需要对每层进行归一化处理，所以会用到batch normalization，其次就是使用BN后能够加快训练速度，提高模型训练精度。


# 使用dropout可以解决什么问题？
- 使用dropout最基本能解决的问题就是过拟合的问题，它的原理就是随机使每一层部分的神经元失活（不再激活），消除减弱了神经元节点间的联合适应性，增强了泛化能力。同时还可以起到提高训练效率的作用。



